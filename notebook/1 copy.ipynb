{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e25ccdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 1. IMPORTS AND SETUP\n",
    "# =====================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import calendar\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, MultiLabelBinarizer, StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.inspection import permutation_importance, PartialDependenceDisplay\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0abcef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 2. LOAD DATA\n",
    "# =====================================================\n",
    "df = pd.read_csv('data/dataset.csv')\n",
    "df_copy = df.copy()\n",
    "\n",
    "# =====================================================\n",
    "# 3. CLEANING & PREPROCESSING\n",
    "# =====================================================\n",
    "# Clean strings (removes whitespace, leading/trailing underscores)\n",
    "for col in df_copy.columns:\n",
    "    if df_copy[col].dtype == 'object':\n",
    "        df_copy[col] = df_copy[col].str.strip().str.strip('_')\n",
    "\n",
    "# Specific column fixes\n",
    "df_copy['Customer_ID'] = df_copy['Customer_ID'].str.lstrip('CUS_0x')\n",
    "df_copy['Payment_Behaviour'] = df_copy['Payment_Behaviour'].replace('!@9#%8', np.nan)\n",
    "df_copy['Occupation'] = df_copy['Occupation'].replace('', np.nan)\n",
    "df_copy['Credit_Mix'] = df_copy['Credit_Mix'].replace('', np.nan)\n",
    "df_copy['Payment_of_Min_Amount'].replace('NM', 'No', inplace=True)\n",
    "\n",
    "# Month name to number\n",
    "month_to_num = {m:i for i,m in enumerate(calendar.month_name) if m}\n",
    "df_copy['Month'] = df_copy['Month'].map(month_to_num)\n",
    "\n",
    "# Drop irrelevant privacy columns\n",
    "df_copy.drop(columns=[c for c in [\"ID\",\"SSN\",\"Name\"] if c in df_copy.columns], inplace=True)\n",
    "\n",
    "# =====================================================\n",
    "# 4. TYPE CONVERSION & RANGE VALIDATION\n",
    "# =====================================================\n",
    "float_cols = ['Annual_Income','Interest_Rate', 'Monthly_Inhand_Salary', 'Changed_Credit_Limit',\n",
    "              'Outstanding_Debt','Credit_Utilization_Ratio','Total_EMI_per_month',\n",
    "              'Amount_invested_monthly','Monthly_Balance']\n",
    "\n",
    "int_cols = ['Age','Num_Bank_Accounts', 'Num_Credit_Card', 'Num_of_Loan',\n",
    "            'Delay_from_due_date','Num_of_Delayed_Payment','Num_Credit_Inquiries']\n",
    "\n",
    "for col in float_cols:\n",
    "    df_copy[col] = pd.to_numeric(df_copy[col], errors='coerce')\n",
    "\n",
    "for col in int_cols:\n",
    "    df_copy[col] = pd.to_numeric(df_copy[col], errors='coerce')\n",
    "\n",
    "# Drop out-of-range values \n",
    "for col in ['Age','Num_Bank_Accounts','Num_Credit_Card','Num_of_Loan',\n",
    "            'Num_of_Delayed_Payment','Num_Credit_Inquiries','Interest_Rate']:\n",
    "    df_copy.loc[(df_copy[col]<0)|(df_copy[col]>100), col] = np.nan\n",
    "df_copy.loc[(df_copy['Num_Bank_Accounts']>60)|(df_copy['Num_Bank_Accounts']<0), 'Num_Bank_Accounts'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ead25e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "median_value = df_copy['Monthly_Balance'].median()\n",
    "df_median_imputed = df_copy.copy()\n",
    "df_median_imputed['Monthly_Balance'].fillna(median_value, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1819e9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 5. IMPUTATION (GROUPWISE)\n",
    "# =====================================================\n",
    "def impute_by_customer_median(df, columns):\n",
    "    group_medians = df.groupby('Customer_ID')[columns].median()\n",
    "    for col in columns:\n",
    "        df[col] = df[col].fillna(df['Customer_ID'].map(group_medians[col]))\n",
    "    return df\n",
    "\n",
    "def impute_by_customer_mode(df, columns):\n",
    "    for col in columns:\n",
    "        modes = df.groupby('Customer_ID')[col].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan)\n",
    "        df[col] = df[col].fillna(df['Customer_ID'].map(modes))\n",
    "    return df\n",
    "\n",
    "df_copy = impute_by_customer_median(df_copy, float_cols + int_cols)\n",
    "cat_cols = df_copy.select_dtypes(include='object').columns.tolist()\n",
    "df_copy = impute_by_customer_mode(df_copy, [c for c in cat_cols if c!='Credit_History_Age'])\n",
    "\n",
    "# Impute global mode for 'Type_of_Loan'\n",
    "if 'Type_of_Loan' in df_copy.columns:\n",
    "    mode_value = df_copy['Type_of_Loan'].mode()[0]\n",
    "    df_copy['Type_of_Loan'] = df_copy['Type_of_Loan'].fillna(mode_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c395a43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "95724708-fbc0-42e4-b174-ef30f95c9da8",
       "rows": [
        [
         "Customer_ID",
         "0"
        ],
        [
         "Month",
         "0"
        ],
        [
         "Age",
         "0"
        ],
        [
         "Occupation",
         "0"
        ],
        [
         "Annual_Income",
         "0"
        ],
        [
         "Monthly_Inhand_Salary",
         "0"
        ],
        [
         "Num_Bank_Accounts",
         "0"
        ],
        [
         "Num_Credit_Card",
         "0"
        ],
        [
         "Interest_Rate",
         "0"
        ],
        [
         "Num_of_Loan",
         "0"
        ],
        [
         "Type_of_Loan",
         "0"
        ],
        [
         "Delay_from_due_date",
         "0"
        ],
        [
         "Num_of_Delayed_Payment",
         "0"
        ],
        [
         "Changed_Credit_Limit",
         "0"
        ],
        [
         "Num_Credit_Inquiries",
         "0"
        ],
        [
         "Credit_Mix",
         "0"
        ],
        [
         "Outstanding_Debt",
         "0"
        ],
        [
         "Credit_Utilization_Ratio",
         "0"
        ],
        [
         "Credit_History_Age",
         "9030"
        ],
        [
         "Payment_of_Min_Amount",
         "0"
        ],
        [
         "Total_EMI_per_month",
         "0"
        ],
        [
         "Amount_invested_monthly",
         "0"
        ],
        [
         "Payment_Behaviour",
         "0"
        ],
        [
         "Monthly_Balance",
         "1696"
        ],
        [
         "Credit_Score",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 25
       }
      },
      "text/plain": [
       "Customer_ID                    0\n",
       "Month                          0\n",
       "Age                            0\n",
       "Occupation                     0\n",
       "Annual_Income                  0\n",
       "Monthly_Inhand_Salary          0\n",
       "Num_Bank_Accounts              0\n",
       "Num_Credit_Card                0\n",
       "Interest_Rate                  0\n",
       "Num_of_Loan                    0\n",
       "Type_of_Loan                   0\n",
       "Delay_from_due_date            0\n",
       "Num_of_Delayed_Payment         0\n",
       "Changed_Credit_Limit           0\n",
       "Num_Credit_Inquiries           0\n",
       "Credit_Mix                     0\n",
       "Outstanding_Debt               0\n",
       "Credit_Utilization_Ratio       0\n",
       "Credit_History_Age          9030\n",
       "Payment_of_Min_Amount          0\n",
       "Total_EMI_per_month            0\n",
       "Amount_invested_monthly        0\n",
       "Payment_Behaviour              0\n",
       "Monthly_Balance             1696\n",
       "Credit_Score                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4b5d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 6. CONVERT CREDIT HISTORY AGE TO MONTHS\n",
    "# =====================================================\n",
    "def convert_age_to_months(age_str):\n",
    "    if pd.isna(age_str) or age_str in ['NA', '_', '']:\n",
    "        return np.nan\n",
    "    match = re.match(r\"(\\d+)\\s*Years\\s*and\\s*(\\d+)\\s*Months\", str(age_str))\n",
    "    if match:\n",
    "        years = int(match.group(1))\n",
    "        months = int(match.group(2))\n",
    "        return years*12 + months\n",
    "    return np.nan\n",
    "\n",
    "if 'Credit_History_Age' in df_copy.columns:\n",
    "    df_copy['Credit_History_Age_Months'] = df_copy['Credit_History_Age'].apply(convert_age_to_months)\n",
    "    df_copy['Credit_History_Age_Months'] = df_copy['Credit_History_Age_Months'].fillna(df_copy['Credit_History_Age_Months'].median())\n",
    "    df_copy.drop(columns=['Credit_History_Age'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67fd5c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature list: ['Month', 'Age', 'Occupation', 'Annual_Income', 'Monthly_Inhand_Salary', 'Interest_Rate', 'Payment_of_Min_Amount', 'Payment_Behaviour', 'Credit_Score', 'Auto Loan', 'Credit-Builder Loan', 'Debt Consolidation Loan', 'Home Equity Loan', 'Mortgage Loan', 'Not Specified', 'Payday Loan', 'Personal Loan', 'Student Loan', 'DTI', 'EMI_to_Income', 'Invest_to_Income', 'Balance_to_Income', 'Avg_Delay_if_Delayed', 'Has_Delays', 'High_Utilization', 'Total_Financial_Products', 'Inquiries_per_Year', 'Limit_Decrease_Flag', 'Large_Limit_Change', 'Num_Loan_Types']\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# 7. ENCODING & FEATURE ENGINEERING\n",
    "# =====================================================\n",
    "\n",
    "\n",
    "# MultiLabelBinarizer for loan types\n",
    "def split_loan_types(val):\n",
    "    if pd.isna(val): return []\n",
    "    return [loan.strip() for loan in str(val).replace(\" and \", \", \").split(\",\") if loan.strip()]\n",
    "if 'Type_of_Loan' in df_copy.columns:\n",
    "    df_copy[\"Type_of_Loan_List\"] = df_copy[\"Type_of_Loan\"].apply(split_loan_types)\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    loan_dummies = pd.DataFrame(mlb.fit_transform(df_copy['Type_of_Loan_List']),\n",
    "                                columns=mlb.classes_,index=df_copy.index)\n",
    "    df_copy = pd.concat([df_copy, loan_dummies], axis=1)\n",
    "df_copy.drop(columns=['Type_of_Loan','Type_of_Loan_List'], inplace=True)\n",
    "\n",
    "# Outlier capping (choose appropriate quantiles for your data)\n",
    "# for feature in ['Annual_Income','Age','Monthly_Inhand_Salary']:\n",
    "#     lower = df_copy[feature].quantile(0.06)\n",
    "#     upper = df_copy[feature].quantile(0.94)\n",
    "#     df_copy[feature+'_Capped'] = df_copy[feature].clip(lower=lower, upper=upper)\n",
    "#     df_copy.drop(columns=feature, inplace=True)\n",
    "\n",
    "# # Log transformation (for capped features)\n",
    "# for feature in ['Annual_Income_Capped','Monthly_Inhand_Salary_Capped', 'Age_Capped']:\n",
    "#     df_copy[feature+'_log'] = np.log1p(df_copy[feature])\n",
    "\n",
    "# Feature engineering: ratios and flags\n",
    "df_copy['DTI'] = df_copy['Total_EMI_per_month'] / df_copy['Monthly_Inhand_Salary']\n",
    "df_copy['EMI_to_Income'] = df_copy['Outstanding_Debt'] / df_copy['Annual_Income']\n",
    "df_copy['Invest_to_Income'] = df_copy['Amount_invested_monthly'] / df_copy['Monthly_Inhand_Salary']\n",
    "df_copy['Balance_to_Income'] = df_copy['Monthly_Balance'] / df_copy['Monthly_Inhand_Salary']\n",
    "df_copy['Avg_Delay_if_Delayed'] = df_copy['Delay_from_due_date'] / df_copy['Num_of_Delayed_Payment'].replace(0, 1)\n",
    "df_copy['Has_Delays'] = (df_copy['Num_of_Delayed_Payment'] > 0).astype(int)\n",
    "df_copy['High_Utilization'] = (df_copy['Credit_Utilization_Ratio'] > 0.7).astype(int)\n",
    "df_copy['Total_Financial_Products'] = df_copy['Num_Bank_Accounts'] + df_copy['Num_Credit_Card'] + df_copy['Num_of_Loan']\n",
    "df_copy['Inquiries_per_Year'] = df_copy['Num_Credit_Inquiries'] / (df_copy['Credit_History_Age_Months']/12).replace(0, 1)\n",
    "df_copy['Limit_Decrease_Flag'] = (df_copy['Changed_Credit_Limit'] < 0).astype(int)\n",
    "df_copy['Large_Limit_Change'] = (df_copy['Changed_Credit_Limit'].abs() > 20).astype(int)\n",
    "loan_cols = [col for col in df_copy.columns if col.endswith(\"Loan\")]\n",
    "df_copy['Num_Loan_Types'] = df_copy[loan_cols].sum(axis=1)\n",
    "\n",
    "# Drop columns that have been fully replaced with engineered features\n",
    "drop_cols = ['Total_EMI_per_month','Outstanding_Debt','Amount_invested_monthly','Monthly_Balance',\n",
    "             'Delay_from_due_date','Num_of_Delayed_Payment','Credit_Utilization_Ratio','Num_Bank_Accounts',\n",
    "             'Num_Credit_Card','Num_of_Loan','Num_Credit_Inquiries','Credit_History_Age_Months',\n",
    "             'Changed_Credit_Limit','Credit_Mix']\n",
    "df_copy.drop(columns=[col for col in drop_cols if col in df_copy.columns], inplace=True)\n",
    "\n",
    "# Drop Customer_ID if present\n",
    "if 'Customer_ID' in df_copy.columns:\n",
    "    df_copy.drop(columns=['Customer_ID'], inplace=True)\n",
    "\n",
    "df_copy.to_csv('data/cleaned_dataset.csv', index=False)\n",
    "print(\"Final feature list:\", df_copy.columns.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43f954f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 1. Split Data\n",
    "# =====================================================\n",
    "X = df_copy.drop(columns=['Credit_Score'])\n",
    "y = df_copy['Credit_Score']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# 2. Build Preprocessing Pipeline\n",
    "# =====================================================\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "num_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ('cat', OneHotEncoder(drop='first'), cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# 3. Transform Data, Reduce Correlation\n",
    "# =====================================================\n",
    "preprocessor.fit(X_train)\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "# Transform train and test sets\n",
    "X_train_t = preprocessor.transform(X_train)\n",
    "X_test_t = preprocessor.transform(X_test)\n",
    "X_train_df = pd.DataFrame(X_train_t, columns=feature_names)\n",
    "X_test_df = pd.DataFrame(X_test_t, columns=feature_names)\n",
    "\n",
    "# Correlation-based feature pruning\n",
    "corr_matrix = X_train_df.corr().abs()\n",
    "redundant = set()\n",
    "threshold = 0.9\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if corr_matrix.iloc[i, j] > threshold:\n",
    "            redundant.add(corr_matrix.columns[j])\n",
    "\n",
    "X_train_reduced = X_train_df.drop(columns=list(redundant))\n",
    "X_test_reduced = X_test_df.drop(columns=list(redundant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13e09b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff996fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.82345\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.80      0.78      0.79      3566\n",
      "        Poor       0.81      0.85      0.83      5799\n",
      "    Standard       0.84      0.83      0.83     10635\n",
      "\n",
      "    accuracy                           0.82     20000\n",
      "   macro avg       0.82      0.82      0.82     20000\n",
      "weighted avg       0.82      0.82      0.82     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_reduced, y_train)\n",
    "y_pred = rf.predict(X_test_reduced)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d52ad33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "Best parameters: {'max_depth': None, 'max_features': 7, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best CV score: 0.8008499716561613\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best parameters from Randomized Search: {'n_estimators': 200, 'min_samples_split': 2, 'max_features': 7, 'max_depth': None}\n",
      "Best CV score from Randomized Search: 0.8008499716561613\n"
     ]
    }
   ],
   "source": [
    "# Grid Search with reduced features\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],  # fewer options\n",
    "    'max_depth': [8, 15, None],  # smaller set\n",
    "    'min_samples_split': [2, 10], \n",
    "    'max_features': ['auto', 7]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3, verbose=2, n_jobs=4)\n",
    "grid.fit(X_train_reduced, y_train)\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best CV score:\", grid.best_score_)\n",
    "rf_best = grid.best_estimator_\n",
    "\n",
    "random = RandomizedSearchCV(RandomForestClassifier(random_state=42), param_distributions=param_grid, n_iter=10, cv=3, verbose=2, n_jobs=4)\n",
    "random.fit(X_train_reduced, y_train)\n",
    "print(\"Best parameters from Randomized Search:\", random.best_params_)\n",
    "print(\"Best CV score from Randomized Search:\", random.best_score_)\n",
    "rf_random_best = random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff6275db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.82615\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.81      0.78      0.79      3566\n",
      "        Poor       0.81      0.85      0.83      5799\n",
      "    Standard       0.84      0.83      0.84     10635\n",
      "\n",
      "    accuracy                           0.83     20000\n",
      "   macro avg       0.82      0.82      0.82     20000\n",
      "weighted avg       0.83      0.83      0.83     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_params = {\n",
    "    'max_depth': None,\n",
    "    'max_features': 7,\n",
    "    'min_samples_split': 2,\n",
    "    'n_estimators': 200,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Initialize the model with best parameters\n",
    "rf_best = RandomForestClassifier(**best_params)\n",
    "\n",
    "# Fit the model on the full training data again\n",
    "rf_best.fit(X_train_reduced, y_train)\n",
    "y_pred = rf_best.predict(X_test_reduced)\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6976a79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Features:\n",
      "num__Interest_Rate: 0.1111\n",
      "num__Inquiries_per_Year: 0.0984\n",
      "num__EMI_to_Income: 0.0785\n",
      "num__Total_Financial_Products: 0.0712\n",
      "num__Avg_Delay_if_Delayed: 0.0657\n",
      "num__Invest_to_Income: 0.0592\n",
      "num__Annual_Income: 0.0560\n",
      "num__Monthly_Inhand_Salary: 0.0554\n",
      "num__DTI: 0.0550\n",
      "num__Age: 0.0489\n",
      "Random Forest Cross-validation scores: [0.81075   0.8103125 0.8134375 0.81      0.8090625]\n",
      "Mean CV accuracy: 0.8107125\n"
     ]
    }
   ],
   "source": [
    "# Feature importances\n",
    "importances = rf.feature_importances_\n",
    "feat_ranks = sorted(zip(X_train_reduced.columns, importances), key=lambda x: x[1], reverse=True)\n",
    "print(\"Top 10 Features:\")\n",
    "for f, v in feat_ranks[:10]:\n",
    "    print(f\"{f}: {v:.4f}\")\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(rf, X_train_reduced, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Random Forest Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d907e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # =====================================================\n",
    "# # 5. Feature/Model Interpretation & Visualization\n",
    "# # =====================================================\n",
    "# import matplotlib.pyplot as plt\n",
    "# indices = importances.argsort()[::-1]\n",
    "# plt.figure(figsize=(10,6))\n",
    "# plt.bar(range(len(importances)), importances[indices], align=\"center\")\n",
    "# plt.xticks(range(len(importances)), X_train_reduced.columns[indices], rotation=90)\n",
    "# plt.title(\"Feature Importances (Random Forest)\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c03acba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance, PartialDependenceDisplay\n",
    "result = permutation_importance(rf, X_test_reduced, y_test, n_repeats=10, random_state=42)\n",
    "perm_sorted_idx = result.importances_mean.argsort()[::-1]\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(range(len(result.importances_mean)), result.importances_mean[perm_sorted_idx], align=\"center\")\n",
    "plt.xticks(range(len(result.importances_mean)), X_test_reduced.columns[perm_sorted_idx], rotation=90)\n",
    "plt.title(\"Permutation Feature Importance\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4376c5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PartialDependenceDisplay.from_estimator(rf, X_test_reduced, [0, 1], feature_names=X_test_reduced.columns, target=0)\n",
    "# plt.show()\n",
    "\n",
    "test_results = X_test_reduced.copy()\n",
    "test_results['True_Score'], test_results['Pred_Score'] = y_test, y_pred\n",
    "misclassified = test_results[test_results['True_Score'] != test_results['Pred_Score']]\n",
    "print(\"Sample misclassified cases:\")\n",
    "misclassified.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d5b535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 6. Save Model and Feature List For Deployment\n",
    "# =====================================================\n",
    "import joblib\n",
    "\n",
    "joblib.dump(rf_best, \"credit_rf_model.pkl\")\n",
    "joblib.dump(X_train_reduced.columns.tolist(), \"feature_columns.pkl\")\n",
    "\n",
    "def predict_new(data_row):\n",
    "    model = joblib.load(\"credit_rf_model.pkl\")\n",
    "    feature_list = joblib.load(\"feature_columns.pkl\")\n",
    "    X_new = pd.DataFrame([data_row])[feature_list]\n",
    "    pred = model.predict(X_new)[0]\n",
    "    class_map = {0: 'Poor', 1: 'Standard', 2: 'Good'}\n",
    "    return class_map.get(int(pred), pred)\n",
    "\n",
    "print(\"Credit scoring project: End-to-End code complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
